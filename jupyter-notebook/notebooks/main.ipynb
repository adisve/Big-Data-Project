{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reddit Comments from May 2015\n",
    "\n",
    "This dataset contains every publicly available Reddit comment for the month of May, 2015. Approximately 37 million comments were made by 2.7 million unique authors, stored in a ~15 GB compressed file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/12/03 21:40:44 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+---------+\n",
      "|                body|score|subreddit|\n",
      "+--------------------+-----+---------+\n",
      "|Then you got your...| 6761|AskReddit|\n",
      "|Thanks man and al...| 5849|AskReddit|\n",
      "|We had an office ...| 5776|AskReddit|\n",
      "|OP are you alrigh...| 5767|AskReddit|\n",
      "|So she's pregnant...| 5762|AskReddit|\n",
      "|Forum based websi...| 5710|AskReddit|\n",
      "|It would be the i...| 5699|AskReddit|\n",
      "|         Â¯\\\\_(ãƒ„)_/Â¯| 5673|AskReddit|\n",
      "|HEY! THAT'S ME!!!...| 5642|    funny|\n",
      "|Being fucking lat...| 5570|AskReddit|\n",
      "+--------------------+-----+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2:=======================================================> (40 + 1) / 41]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+------------------+---------+\n",
      "|summary|                body|             score|subreddit|\n",
      "+-------+--------------------+------------------+---------+\n",
      "|  count|            37868338|          37868338| 37868338|\n",
      "|   mean|                 NaN| 5.742138960521584| Infinity|\n",
      "| stddev|                 NaN|48.223446067798875|      NaN|\n",
      "|    min|\u0004How does DNS com...|              -964|  007chan|\n",
      "|    max|              ó¾ ³ó¾ ¶ðŸ”ž|              6761|     zzzz|\n",
      "+-------+--------------------+------------------+---------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from spark.dataset import Dataset\n",
    "\n",
    "\n",
    "hdfs_path = \"hdfs://namenode:9000/user/spark/reddit_comments/\"\n",
    "spark_master = \"spark://spark-master:7077\"\n",
    "\n",
    "dataset = Dataset(hdfs_path, spark_master)\n",
    "dataset.pre_process()\n",
    "\n",
    "# Test\n",
    "dataset.dataframe.sort(\"score\", ascending=False).show(10)\n",
    "dataset.dataframe.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import lower, col, trim, explode, split, collect_list\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download(\"stopwords\")\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "df = dataset.dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = df.select(explode(split(lower(col(\"body\")), \" \")).alias(\"body\"))\n",
    "filtered_words = words.withColumn(\"body\", trim(words.body)).filter(~col(\"body\").isin(stop_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "from pyspark.sql.functions import create_map, desc\n",
    "\n",
    "wordcloud = WordCloud(background_color=\"white\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 7:===================================================>       (7 + 1) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+\n",
      "|                body|    count|\n",
      "+--------------------+---------+\n",
      "|                NULL|389036178|\n",
      "|                    | 12116731|\n",
      "|                  \u0001Â¼|        1|\n",
      "|                  \u0001ï¿½|        1|\n",
      "|          \u0003reduction|        1|\n",
      "|                \u0004how|        1|\n",
      "|                  \\b|        1|\n",
      "|                \\b\\b|        1|\n",
      "|           \\bmuscled|        1|\n",
      "|               \\bthe|        1|\n",
      "|              \\bwut?|        1|\n",
      "|                  \\t|       26|\n",
      "|              \\t\\t\\t|        2|\n",
      "|            \\t\\t\\t\\t|        1|\n",
      "|        \\t\\t\\t\\t\\t\\t|        1|\n",
      "|  \\t\\t\\t\\t\\t\\t\\t\\t\\t|        1|\n",
      "|\\t\\t\\t\\t\\t\\t\\t\\t\\...|        1|\n",
      "|           \\t\\t\\tyou|        1|\n",
      "|        \\t\\tpreload:|        1|\n",
      "|                 \\t\"|        1|\n",
      "+--------------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "filtered_words.cube(\"body\").count().orderBy(\"body\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
